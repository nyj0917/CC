##하둡설치하기 ( root 계정으로 바꾸고 하기 )
```
1. 하둡 다운로드(wget 사용)

    cd ~/Downloads
    
    (64비트인 경우)
    wget —no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u5-b13/jdk-8u5-linux-x64.tar.gz

    (32비트인 경우)
    wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-i586.tar.gz"

    cd ~/Downloads/
    tar –zxvf jdk-8u5-linux-x64.tar.gz     // 압축 풀기
    mkdir /usr/java
    mv jdk1.8.0_05 /usr/java/jdk1.8        // 파일 복사 jdk를 java밑으로
    
```
```
2. 환경변수 설정하기

    vi /etc/profile  맨 밑에 추가

    export JAVA_HOME=/usr/java/jdk1.8
    export PATH=$JAVA_HOME/bin:$PATH
    export CLASSPATH=$CLASSPATH:$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jar

    source /etc/profile
    @@ source 명령어는 " . "과 같다.  
    " . " 을 사용하면 다시 로그인 하고 실행해야 변하지만 
    source 명령어를 사용하면 로그아웃 하지않고 바로 변한것을 확인 할 수 있음.
    
```
```
3. 계정 추가하기

    useradd hadoop
    su - hadoop
    
    @@ SSH 설치 및 공개 키 설정  
    @@ Hadoop클러스터에서 Master와 Slave들 간에 통신은 SSH를 이용한다. 
    @@ Master에서 암호없이 Slave에 접속하기 위해서 공개 키가 필요하다.
    
    ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa            
    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys     
    chmod 0600 ~/.ssh/authorized_keys                   
    @@ ssh는 텔넷과 같은 원격접속을 말한다. 
    @@ -keygen : 클라이언트 서버에서 계정별로 Key값을 생성하여 접근하려는 대상서버와 클라이언트 서버간에 생성된 key값을 매치하여 비밀번호 없이 접근하는 방식
    @@ 암호화방식 dsa, rsa

```
```
4.  ssh 연결 확인
    ssh localhost
    exit
    (ctrl + d)

```
```
5. 하둡다운로드 (wget 이용)
    cd /home
    mkdir hadoop
    cd hadoop
    wget http://apache.tt.co.kr/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz
    tar -zxvf hadoop-2.7.1.tar.gz
    
```
```
6. 환경설정 ( hadoop 계정에서 실행 )

    $vi ~/.bashrc
    @@ 밑에 추가하기
    export JAVA_HOME=/usr/java/jdk1.8
    export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar
    export HADOOP_HOME=/home/hadoop/hadoop-2.7.1
    export HADOOP_INSTALL=$HADOOP_HOME
    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME
    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export HADOOP_YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
    export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH

    $source $HOME/.bashrc

```
```
7. 설정값 추가하기

# (하둡을 구동하는 스크립트에서 사용되는 환경 변수)
    vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh 
    export JAVA_HOME=/usr/java/jdk1.8


    # Hadoop 설치 후 로그파일, 네트워크 튜닝, I/O튜닝, 파일 시스템 튜닝, 압축 등과 같이 기본적인 하부 시스템 설정
    # 맵리듀스에서도 공통으로 사용

    vi $HADOOP_HOME/etc/hadoop/core-site.xml

    <configuration> 
        <property>
            <name>fs.default.name</name>
            <value>hdfs://localhost:9000</value>
        </property>
    </configuration> 


    # (네임노드, 보조 네임노드, 데이터노드 등과 같은 HDFS 데몬을 위한 환경 설정 구성)
    vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml

    <configuration> 
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>

        <property>
            <name>dfs.name.dir</name>
            <value>file:///home/hadoop/hadoopdata/hdfs/namenode</value>
        </property>

        <property>
            <name>dfs.data.dir</name>
            <value>file:///home/hadoop/hadoopdata/hdfs/datanode</value>
        </property>
    </configuration>         


    cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template $HADOOP_HOME/etc/hadoop/mapred-site.xml



    # (잡트래커와 테스크트래커와 같은 맵리듀스 데몬을 위한 환경 설정 구성)
    vi  $HADOOP_HOME/etc/hadoop/mapred-site.xml

    <configuration> 
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    </configuration> 


    vi $HADOOP_HOME/etc/hadoop/yarn-site.xml

    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>


    set JAVA_HOME

```
```
8. 하둡시작

    hdfs namenode -format
    start-dfs.sh
    start-yarn.sh

```
```
9. 간단한 txt 파일 만들기 ( hadoop home 안에서 )
    # 테스트 문서 제작
    vim test.txt

    # 아래 두줄을 test.txt 에 넣어주면 됨
    # 테스트용 문서를 옮겨놓고 사용해도 됨)
    i am a boy
    you are a girl

    hdfs dfs -mkdir /user   # user 디렉토리를 만듬 # exist directory 인 경우는 패스하면 됨
    hdfs dfs -mkdir /user/hadoop   # hadoop 디렉토리를 만듬 # exist directory 인 경우는 패스하면 됨
    hdfs dfs -mkdir /user/hadoop/input   # input 디렉토리를 만듬
    hdfs dfs -put test.txt /user/hadoop/input   # test.txt 파일을 input 디렉토리에 넣음

    # Word Count java 코드 작성( github 에서 WordCount.java 파일 다운로드)
    wget https://raw.githubusercontent.com/kowonsik/CCL/master/WordCount.java

    # WordCount.java compile
    hadoop com.sun.tools.javac.Main WordCount.java

    # jar 파일 만들기
    jar -cf wc.jar WordCount*.class

    # Word Count 실행
    hadoop jar wc.jar WordCount /user/hadoop/input /output

    # 하둡 기본명령어
    hadoop fs -ls /   # 모든 디렉토리 확인
    hadoop fs -ls /output   # output 디렉토리 확인
    hadoop fs -mkdir ......
    hadoop fs -cat ......
    hadoop fs -cp 1.파일을 2.여기에복사
    hadoop fs -mv 1.파일을 2.여기로옮김
    hadoop fs -rm .......
    hadoop fs -rmr ......

    # 결과 확인
    hdfs dfs -cat /output/part-r-00000
    
```
